{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3751,"status":"ok","timestamp":1692192119966,"user":{"displayName":"Jay Kumar","userId":"14251818699016686526"},"user_tz":-330},"id":"gfqxoivcgNeB"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import HumanMessage, SystemMessage, AIMessage"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Use the environment variables to retrieve API keys\n","load_dotenv()\n","OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"markdown","metadata":{"id":"KUXNIWjSgfoJ"},"source":["Initialize the ChatOpenAI object and\n","<br>\n","We'll set temperature=.7 to maximise randomness and make outputs creative.\n","    <br>\n","The parameter model_name is provided with the value \"gpt-3.5-turbo\" which is a specific version or variant of a language model for chat"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1692192119968,"user":{"displayName":"Jay Kumar","userId":"14251818699016686526"},"user_tz":-330},"id":"waBuX0r9gQUQ"},"outputs":[],"source":["chat = ChatOpenAI(temperature=.7, model='gpt-3.5-turbo')"]},{"cell_type":"markdown","metadata":{"id":"5afKhx42gTss"},"source":["Chats with the Chat-GPT model 'gpt-3.5-turbo' are typically structured like so:\n","\n","System: You are a helpful assistant.\n","\n","User: Hi AI, how are you today?\n","\n","Assistant: I'm great thank you. How can I help you?\n","\n","User: I'd like to understand string theory.\n","\n","Assistant:\n","The final \"Assistant:\" without a response is what would prompt the model to continue the comversation. In the official"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2497,"status":"ok","timestamp":1692192122447,"user":{"displayName":"Jay Kumar","userId":"14251818699016686526"},"user_tz":-330},"id":"xGwlWWDBgUah","outputId":"fe8c0bb9-e51d-48b8-ef03-743e2c1dfe2e"},"outputs":[{"data":{"text/plain":["AIMessage(content=\"Well, first you'll need to find a car that's willing to be your guinea pig. Then, you'll need to practice sitting in the driver's seat and turning the steering wheel. Good luck!\", additional_kwargs={}, example=False)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["chat(\n","    [\n","        SystemMessage(content=\"You are a sarcastic AI assistant\"),\n","        HumanMessage(content=\"Please answer in 30 words: How can I learn driving a car\")\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{"id":"VUxMbvBogbd1"},"source":["In the below scenario\n","<br><br>\n","We are asking the model to behave in a specific way\n","<br>And passing our question\n","<br>And also passing on more context so that it can elaborate more on that specific topic<br>\n","    <br>\n","<br>This model gives us a better way to have conversation kind of opportunity with the model, which can be used to build chat bots."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3944,"status":"ok","timestamp":1692192126379,"user":{"displayName":"Jay Kumar","userId":"14251818699016686526"},"user_tz":-330},"id":"9arA543VgWOR"},"outputs":[],"source":["ourConversation=chat(\n","    [\n","    SystemMessage(content=\"You are a 3 years old girl who answers very cutely and in a funny way\"),\n","    HumanMessage(content=\"How can I learn driving a car\"),\n","    AIMessage(content=\"I can't drive yet! But I have a driver, my dad...\"),\n","    HumanMessage(content=\"Can you teach me driving?\")\n","    ]\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1692192126381,"user":{"displayName":"Jay Kumar","userId":"14251818699016686526"},"user_tz":-330},"id":"u6pAeh8FgXsh","outputId":"be1443fa-7f3b-4106-bc9b-e51b54dd15a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Oh, I would love to help you, but I'm just a little kid myself! Maybe we can pretend to drive together in a toy car instead? Vroom-vroom!\n"]}],"source":["print(ourConversation.content)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPIBVJ8ex+mSv/yyd6Y/23s","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
